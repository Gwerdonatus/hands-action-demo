ğŸ–ï¸ Hands Action Demo
Real-time Hand Gesture â†’ Desktop Automation (Python + MediaPipe + PyAutoGUI)

This project is a gesture-controlled automation system that uses computer vision to detect hand poses and trigger real desktop actions â€” without touching the keyboard or mouse.

Built with Python, MediaPipe, TensorFlow Lite, and PyAutoGUI, it demonstrates real-time vision processing, gesture classification, and system automation.

âœ¨ Features
ğŸ¯ Hand Gesture Detection

Uses MediaPipe Hands + TensorFlow Lite for fast real-time tracking.

Detects:

ğŸ‘ Thumbs Up

âœŒï¸ Peace Sign

âœ‹ Open Palm

ğŸ‘Š Fist

ğŸ¤² Two Hands

ğŸ‘† Swipe Left / Swipe Right

âš¡ Desktop Automation Actions

Each gesture triggers an OS-level action:

Gesture	Action
âœ‹ Open Palm	Alert beep
ğŸ‘ Thumbs Up	Success beep
âœŒï¸ Peace Sign	Open Chrome
ğŸ¤² Two Hands	Take screenshot
ğŸ‘Š Fist	Close Chrome
ğŸ‘ˆ Swipe Left	Next Tab (Ctrl + Tab)
ğŸ‘‰ Swipe Right	Previous Tab (Ctrl + Shift + Tab)

All actions run instantly using PyAutoGUI, winsound, and OS-specific subprocess calls.

ğŸ§  How It Works

The system runs a loop that:

Captures webcam frames

Runs hand detection â†’ extracts landmarks

Classifies gesture using custom logic

Triggers mapped actions from actions.py

You can customize or add new gestures easily.

ğŸ—‚ï¸ Project Structure
hands-action-demo/
â”‚â”€â”€ actions.py          # Executes system-level actions (Chrome, screenshot, beeps, tabs, volume)
â”‚â”€â”€ gestures.py         # Gesture recognition + classification
â”‚â”€â”€ hand_actions.py     # Main entry point (runs webcam + connections)
â”‚â”€â”€ utils.py            # Helpers
â”‚â”€â”€ config.json         # Stores your Chrome path, Django path, etc.
â”‚â”€â”€ requirements.txt    # Dependencies
â”‚â”€â”€ screenshots/        # Auto-generated screenshots
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore

ğŸš€ Getting Started
1. Install dependencies
pip install -r requirements.txt

2. Add your paths (optional)

Edit config.json:

{
  "chrome_path": "C:/Program Files/Google/Chrome/Application/chrome.exe",
  "django_path": ""
}

3. Run the program
python hand_actions.py


Press q to quit.

ğŸ§© Add Your Own Gestures

Want to add a new gesture like âœï¸ "draw in the air" or ğŸ‘Œ "open VS Code"?

Just edit:

gestures.py â†’ detect gesture

actions.py â†’ execute custom action

This is a great playground to experiment with gesture-controlled UI automation.

ğŸŒŸ Why This Project is Valuable

This repo shows your skills in:

Computer Vision

Real-time systems

Gesture recognition

Automation engineering

Python scripting

OS-level process management

User experience design for hands-free control

This is portfolio-grade material that stands out.

ğŸ“œ License

MIT License.
